{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_123_Introduction_to_Bayesian_Inference.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alex-pakalniskis/DS-Unit-1-Sprint-2-Statistics/blob/master/module3/LS_DS_123_Introduction_to_Bayesian_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygVh4RKaRTLU",
        "colab_type": "text"
      },
      "source": [
        "## T-test Assumptions\n",
        "\n",
        "<https://statistics.laerd.com/statistical-guides/independent-t-test-statistical-guide.php>\n",
        "\n",
        "- Independence of means\n",
        "\n",
        "Are the means of our voting data independent (do not affect the outcome of one another)?\n",
        "  \n",
        "The best way to increase the likelihood of our means being independent is to randomly sample (which we did not do).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x24R7InMRpTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "?ttest_ind"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm7-x07WRrxF",
        "colab_type": "text"
      },
      "source": [
        "- \"Homogeneity\" of Variance? \n",
        "\n",
        "Is the magnitude of the variance between the two roughly the same?\n",
        "\n",
        "I think we're OK on this one for the voting data, although it probably could be better, one party was larger than the other.\n",
        "\n",
        "If we suspect this to be a problem then we can use Welch's T-test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyXIuC2ERt92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "?ttest_ind"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4tP02TPRwTX",
        "colab_type": "text"
      },
      "source": [
        "- \"Dependent Variable\" (sample means) are Distributed Normally\n",
        "\n",
        "<https://stats.stackexchange.com/questions/9573/t-test-for-non-normal-when-n50>\n",
        "\n",
        "Lots of statistical tests depend on normal distributions. We can test for normality using Scipy as was shown above.\n",
        "\n",
        "This assumption is often assumed even if the assumption is a weak one. If you strongly suspect that things are not normally distributed, you can transform your data to get it looking more normal and then run your test. This problem typically goes away for large sample sizes (yay Central Limit Theorem) and is often why you don't hear it brought up. People declare the assumption to be satisfied either way. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5InPvPvR48G",
        "colab_type": "text"
      },
      "source": [
        "## Degrees of Freedom:\n",
        "\n",
        "<https://blog.minitab.com/blog/statistics-and-quality-data-analysis/what-are-degrees-of-freedom-in-statistics>\n",
        "\n",
        "![Sample vs Population Variance](https://standard-deviation-calculator.com/wp-content/uploads/2018/03/sample-variance-formula-descriptive-statistics-54-638-cb1374419364.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7OLbevlbd_Z",
        "colab_type": "text"
      },
      "source": [
        "# Lambda School Data Science Module 123\n",
        "\n",
        "## Introduction to Bayesian Inference\n",
        "\n",
        "!['Detector! What would the Bayesian statistician say if I asked him whether the--' [roll] 'I AM A NEUTRINO DETECTOR, NOT A LABYRINTH GUARD. SERIOUSLY, DID YOUR BRAIN FALL OUT?' [roll] '... yes.'](https://imgs.xkcd.com/comics/frequentists_vs_bayesians.png)\n",
        "\n",
        "*[XKCD 1132](https://www.xkcd.com/1132/)*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mz8p08BsN6p",
        "colab_type": "text"
      },
      "source": [
        "## Prepare - Bayes' Theorem and the Bayesian mindset\n",
        "\n",
        "Bayes' theorem possesses a near-mythical quality - a bit of math that somehow magically evaluates a situation. But this mythicalness has more to do with its reputation and advanced applications than the actual core of it - deriving it is actually remarkably straightforward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa-jzYp9i8La",
        "colab_type": "text"
      },
      "source": [
        "### The Law of Total Probability\n",
        "\n",
        "By definition, the total probability of all outcomes (events) if some variable (event space) $A$ is 1. That is:\n",
        "\n",
        "$$P(A) = \\sum_n P(A_n) = 1$$\n",
        "\n",
        "The law of total probability takes this further, considering two variables ($A$ and $B$) and relating their marginal probabilities (their likelihoods considered independently, without reference to one another) and their conditional probabilities (their likelihoods considered jointly). A marginal probability is simply notated as e.g. $P(A)$, while a conditional probability is notated $P(A|B)$, which reads \"probability of $A$ *given* $B$\".\n",
        "\n",
        "The law of total probability states:\n",
        "\n",
        "$$P(A) = \\sum_n P(A | B_n) P(B_n)$$\n",
        "\n",
        "In words - the total probability of $A$ is equal to the sum of the conditional probability of $A$ on any given event $B_n$ times the probability of that event $B_n$, and summed over all possible events in $B$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhycNr-Sbeie",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "### The Law of Conditional Probability\n",
        "\n",
        "What's the probability of something conditioned on something else? To determine this we have to go back to set theory and think about the intersection of sets:\n",
        "\n",
        "The formula for actual calculation:\n",
        "\n",
        "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
        "\n",
        "![Visualization of set intersection](https://upload.wikimedia.org/wikipedia/commons/9/99/Venn0001.svg)\n",
        "\n",
        "Think of the overall rectangle as the whole probability space, $A$ as the left circle, $B$ as the right circle, and their intersection as the red area. Try to visualize the ratio being described in the above formula, and how it is different from just the $P(A)$ (not conditioned on $B$).\n",
        "\n",
        "We can see how this relates back to the law of total probability - multiply both sides by $P(B)$ and you get $P(A|B)P(B) = P(A \\cap B)$ - replaced back into the law of total probability we get $P(A) = \\sum_n P(A \\cap B_n)$.\n",
        "\n",
        "This may not seem like an improvement at first, but try to relate it back to the above picture - if you think of sets as physical objects, we're saying that the total probability of $A$ given $B$ is all the little pieces of it intersected with $B$, added together. The conditional probability is then just that again, but divided by the probability of $B$ itself happening in the first place.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi45SXVyi_Wt",
        "colab_type": "text"
      },
      "source": [
        "### Bayes Theorem\n",
        "\n",
        "Here is is, the seemingly magic tool:\n",
        "\n",
        "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
        "\n",
        "In words - the probability of $A$ conditioned on $B$ is the probability of $B$ conditioned on $A$, times the probability of $A$ and divided by the probability of $B$. These unconditioned probabilities are referred to as \"prior beliefs\", and the conditioned probabilities as \"updated.\"\n",
        "\n",
        "Why is this important? Scroll back up to the XKCD example - the Bayesian statistician draws a less absurd conclusion because their prior belief in the likelihood that the sun will go nova is extremely low. So, even when updated based on evidence from a detector that is $35/36 = 0.972$ accurate, the prior belief doesn't shift enough to change their overall opinion.\n",
        "\n",
        "### Using Bayes Theorem Iteratively (repeated testing)\n",
        "\n",
        "This example comes from [Wikipedia](https://en.wikipedia.org/wiki/Bayes%27_theorem)\n",
        "\n",
        "There are many ways to apply Bayes' theorem - one less absurd example is to apply it to drug tests. You may think that a drug test that is 100% accurate for true positives (detecting somebody who is a user) is pretty good, but what if it also has 1% false positive rate (indicating somebody is a user when they're not)? And furthermore, the rate of drug use in the population at large (and thus our prior belief) is 1/200.\n",
        "\n",
        "What is the likelihood somebody really is drunk if they test positive? Some may guess it's 99% - the difference between the true positives and the false positives. But we have a prior belief of the background/true rate of drug use. Sounds like a job for Bayes' theorem!\n",
        "\n",
        "![Bayes Theorem Drug Test Example](https://wikimedia.org/api/rest_v1/media/math/render/svg/95c6524a3736c43e4bae139713f3df2392e6eda9)\n",
        "\n",
        "In other words, the likelihood that somebody is a user given they tested positive on a drug test is only 33.2% - probably much lower than you'd guess. This is why, in practice, it's important to use repeated testing to confirm. If we have the same individual who tested positive the first time take the drug test a second time then the posterior probability from our the first test becomes our new prior during the second application. What is the probability that a person is a drug user after two positive drug tests in a row?\n",
        "\n",
        "Bayes' theorem has been relevant in court cases where proper consideration of evidence was important. Whether it's a drug test, breathalyzer, pregnancy test, doctor's diagnosis, or neutrino detector, we have to take into account **both** the false positive rate and our prior probability in order to calculate the correct conditional probability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGahAQD-q1VA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Probability of testing positive given that you are a user, i.e. true positive rate\n",
        "p_pos_user = 1.0\n",
        "\n",
        "# Probability of being a drug user, i.e. prior probability\n",
        "p_user = 1/200\n",
        "\n",
        "# Probability of testing positive given that you are a non-user, i.e. false positive rate\n",
        "p_pos_non_user = 0.01\n",
        "\n",
        "# Probability of being a non-user, i.e. complement of our prior probability\n",
        "p_non_user = 1 - p_user"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XCSx9cKq1a_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numerator = p_pos_user * p_user\n",
        "\n",
        "denominator = (p_pos_user * p_user) + (p_pos_non_user * p_non_user)\n",
        "\n",
        "# Posterior probability we get after applying Bayes Theorem\n",
        "posterior1 = numerator / denominator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7y05Bbnq1Y6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "82ecfa50-7acb-4da8-e610-d4f490ec47ae"
      },
      "source": [
        "posterior1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33444816053511706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Aus8J01tp-K",
        "colab_type": "text"
      },
      "source": [
        "Test # 2 for person who failed an initial drug test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60x5OCpKq1PH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "229df21c-5c5f-41d4-9839-8b8d363ca299"
      },
      "source": [
        "#Probability of testing positive given that you are a user, i.e. true positive rate\n",
        "p_pos_user = 1.0\n",
        "\n",
        "# Probability of being a drug user given failing a first test, posterior1\n",
        "p_user = posterior1\n",
        "\n",
        "# Probability of testing positive given that you are a non-user, i.e. false positive rate\n",
        "p_pos_non_user = 0.01\n",
        "\n",
        "# Probability of being a non-user given failing a first test, i.e. complement of posterior1\n",
        "p_non_user = 1 - p_user\n",
        "\n",
        "# Bayes stuff\n",
        "numerator = p_pos_user * p_user\n",
        "\n",
        "denominator = (p_pos_user * p_user) + (p_pos_non_user * p_non_user)\n",
        "\n",
        "# Posterior probability we get after applying Bayes Theorem\n",
        "posterior2 = numerator / denominator\n",
        "\n",
        "posterior2"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9804882831650161"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "remttrMnumF2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e4178ebe-e8df-42f8-8ccb-7bf61efd41d4"
      },
      "source": [
        "1-0.9804882831650161"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.019511716834983872"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khUJfUcluO3v",
        "colab_type": "text"
      },
      "source": [
        "**Null hypothesis**: Non-drug user\n",
        "\n",
        "**Alternative hypothesis**: Drug user\n",
        "\n",
        "**Confidence level**: 95%\n",
        "\n",
        "Given a p-value of 0.0195 below the critical value of 0.05, the null hypothesis that this person is a non-drug user is rejected. Results suggest this person is likely a drug user.   \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htI3DGvDsRJF",
        "colab_type": "text"
      },
      "source": [
        "## Live Lecture - Deriving Bayes' Theorem, Calculating Bayesian Confidence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moIJNQ-nbfe_",
        "colab_type": "text"
      },
      "source": [
        "Notice that $P(A|B)$ appears in the above laws - in Bayesian terms, this is the belief in $A$ updated for the evidence $B$. So all we need to do is solve for this term to derive Bayes' theorem. Let's do it together!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke-5EqJI0Tsn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "a6ad96c2-cd81-4066-fa73-6282c7e9fa7e"
      },
      "source": [
        "# Activity 2 - Use SciPy to calculate Bayesian confidence intervals\n",
        "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bayes_mvs.html#scipy.stats.bayes_mvs\n",
        "\n",
        "\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "\n",
        "coinflips = np.random.binomial(n=1, p=0.5, size=100)\n",
        "coinflips"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "       1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAfcuE_qwZ9J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5511808a-b8b4-4ea1-9a67-bec700679bb0"
      },
      "source": [
        "# Frequentist Confidence Intervals\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "  n = len(data)\n",
        "  mean = sum(data) / n\n",
        "  data = np.array(data)\n",
        "  stderr = stats.sem(data)\n",
        "  interval = stderr * stats.t.ppf((1 + confidence) / 2.0, n-1)\n",
        "  return (mean - interval, mean, mean + interval)\n",
        "\n",
        "\n",
        "confidence_interval(coinflips)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.400289346502771, 0.5, 0.599710653497229)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZbH5ys7waAn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9fc31c59-7109-4b33-f97f-96b6f61e2a6d"
      },
      "source": [
        "# Bayesian Confidence Interval\n",
        "CI, _, _ = stats.bayes_mvs(coinflips, alpha=0.95)\n",
        "\n",
        "CI"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mean(statistic=0.5, minmax=(0.400289346502771, 0.599710653497229))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWgWjp3PQ3Sq",
        "colab_type": "text"
      },
      "source": [
        "## Resources\n",
        "\n",
        "Corrected exercise function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1QbmOpNwHU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prob_drunk_given_positive(prob_drunk_prior, false_positive_rate, true_positive_rate):"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRgHqmYIQ9qn",
        "colab_type": "text"
      },
      "source": [
        "- [Worked example of Bayes rule calculation](https://en.wikipedia.org/wiki/Bayes'_theorem#Examples) (helpful as it fully breaks out the denominator)\n",
        "- [Source code for mvsdist in scipy](https://github.com/scipy/scipy/blob/90534919e139d2a81c24bf08341734ff41a3db12/scipy/stats/morestats.py#L139)"
      ]
    }
  ]
}