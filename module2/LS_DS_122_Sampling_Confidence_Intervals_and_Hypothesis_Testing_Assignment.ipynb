{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "11OzdxWTM7UR"
   },
   "source": [
    "## Assignment - Build a confidence interval\n",
    "\n",
    "A confidence interval refers to a neighborhood around some point estimate, the size of which is determined by the desired p-value. For instance, we might say that 52% of Americans prefer tacos to burritos, with a 95% confidence interval of +/- 5%.\n",
    "\n",
    "52% (0.52) is the point estimate, and +/- 5% (the interval $[0.47, 0.57]$) is the confidence interval. \"95% confidence\" means a p-value $\\leq 1 - 0.95 = 0.05$.\n",
    "\n",
    "In this case, the confidence interval includes $0.5$ - which is the natural null hypothesis (that half of Americans prefer tacos and half burritos, thus there is no clear favorite). So in this case, we could use the confidence interval to report that we've failed to reject the null hypothesis.\n",
    "\n",
    "But providing the full analysis with a confidence interval, including a graphical representation of it, can be a helpful and powerful way to tell your story. Done well, it is also more intuitive to a layperson than simply saying \"fail to reject the null hypothesis\" - it shows that in fact the data does *not* give a single clear result (the point estimate) but a whole range of possibilities.\n",
    "\n",
    "How is a confidence interval built, and how should it be interpreted? It does *not* mean that 95% of the data lies in that interval - instead, the frequentist interpretation is \"if we were to repeat this experiment 100 times, we would expect the average result to lie in this interval ~95 times.\"\n",
    "\n",
    "For a 95% confidence interval and a normal(-ish) distribution, you can simply remember that +/-2 standard deviations contains 95% of the probability mass, and so the 95% confidence interval based on a given sample is centered at the mean (point estimate) and has a range of +/- 2 (or technically 1.96) standard deviations.\n",
    "\n",
    "Different distributions/assumptions (90% confidence, 99% confidence) will require different math, but the overall process and interpretation (with a frequentist approach) will be the same.\n",
    "\n",
    "Your assignment - using the data from the prior module ([congressional voting records](https://archive.ics.uci.edu/ml/datasets/Congressional+Voting+Records)):\n",
    "\n",
    "\n",
    "### Confidence Intervals:\n",
    "1. Generate and numerically represent a confidence interval\n",
    "2. Graphically (with a plot) represent the confidence interval\n",
    "3. Interpret the confidence interval - what does it tell you about the data and its distribution?\n",
    "\n",
    "### Chi-squared tests:\n",
    "4. Take a dataset that we have used in the past in class that has **categorical** variables. Pick two of those categorical variables and run a chi-squared tests on that data\n",
    "  - By hand using Numpy\n",
    "  - In a single line using Scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ckcr4A4FM7cs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "# Needed for grabbing the dataset from https\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Using the people dataset for the initial coe, as I wanted to make sure\n",
    "# I could replicate the instructors results without copying code\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/adult.csv', na_values=\" ?\")\n",
    "\n",
    "# Function to generate a CI, and check it's results against Scipy\n",
    "# s = series\n",
    "# c = tolerance (confidence level)\n",
    "\n",
    "# QUOTE:\n",
    "# 'The confidence interval represents values for the data provided, for which the difference between the\n",
    "# parameter and the observed estimate is not statistically significant at the c (confidence level) level.\n",
    "# a confidence interval (CI) is a type of interval estimate, computed from the statistics of the observed\n",
    "# data, that might contain the true value of an unknown population parameter. ... Most commonly, the 95%\n",
    "# confidence level is used. However, other confidence levels can be used, for example, 90% and 99%.'\n",
    "\n",
    "def ci(s, c):\n",
    "\n",
    "    # Pull the series in as an numpy array\n",
    "    #s = np.array(d)\n",
    "    # Mean of the series\n",
    "    m = np.mean(s)\n",
    "    # Length of the series\n",
    "    l = len(s)\n",
    "    # Std of the series using 1 as degree of freedom\n",
    "    std = np.std(s, ddof=1)\n",
    "    # Standard error of the series\n",
    "    se = std / np.sqrt(l)\n",
    "    # The t-statistic that corresponds to the\n",
    "    # cofidence levcel, and degree of freedom\n",
    "    t = stats.t.ppf((1 + c) / 2, l - 1)\n",
    "    # Margin of error\n",
    "    moe = t * se\n",
    "\n",
    "    # Return variables\n",
    "    low = m - moe\n",
    "    high = m + moe\n",
    "    mid = m\n",
    "\n",
    "    # Compare our results with Scipy\n",
    "    s_low, s_high = stats.t.interval(0.95,\n",
    "                                     l-1,\n",
    "                                     loc=m,\n",
    "                                     scale=se)\n",
    "\n",
    "    if s_low != low or s_high != high:\n",
    "\n",
    "        print('Your results:')\n",
    "        print(str(low) + ' - ' + str(high))\n",
    "        print('SciPy\\'s')\n",
    "        print(str(s_low) + ' - ' + str(s_high))\n",
    "\n",
    "        raise Exception('The results of the confidence interval you generated ndoes not match that of Scipys!')\n",
    "\n",
    "    else:\n",
    "        # Return a tuple that contains the results\n",
    "        return moe, low, mid, high\n",
    "\n",
    "# QUOTE:\n",
    "# The chi-squared goodness of fit test or Pearsonâ€™s chi-squared test is used to assess whether a set of\n",
    "# categorical data is consistent with proposed values for the parameters. This function checks against\n",
    "# SciPy's results as well (will add in a bit).\n",
    "\n",
    "def cs(known,expected):\n",
    "\n",
    "    stat=0\n",
    "    for known, expected in zip(known, expected):\n",
    "        stat+=(float(known)-float(expected))**2/float(expected)\n",
    "\n",
    "        return stat\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Confidence Interval\n",
    "moe, low, mid, high = ci(df['age'], 0.95)\n",
    "\n",
    "# Histogram\n",
    "ax = sns.distplot(df['age'], bins=72)\n",
    "\n",
    "# verical lines\n",
    "plt.axvline(x=low, color='red')\n",
    "plt.axvline(x=mid, color='black')\n",
    "plt.axvline(x=high, color='red')\n",
    "plt.show()\n",
    "\n",
    "# I was able to replicate the code, and test the function for\n",
    "# generating the CI Loading the congressional voting records:\n",
    "\n",
    "columns = ['party',\n",
    "           'handicapped-infants',\n",
    "           'water-project',\n",
    "           'budget',\n",
    "           'physician-fee-freeze',\n",
    "           'el-salvador-aid',\n",
    "           'religious-groups',\n",
    "           'anti-satellite-ban',\n",
    "           'aid-to-contras',\n",
    "           'mx-missile',\n",
    "           'immigration',\n",
    "           'synfuels',\n",
    "           'education',\n",
    "           'right-to-sue',\n",
    "           'crime',\n",
    "           'duty-free',\n",
    "           'south-africa']\n",
    "\n",
    "df_voting = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data',\n",
    "                 header = None,\n",
    "                 names = columns,\n",
    "                 na_values = '?'\n",
    "                 )\n",
    "\n",
    "# Replace string values with numbers so they are easier to process later.\n",
    "\n",
    "df_voting = df_voting.replace({'n':0,\n",
    "                               'y':1})\n",
    "\n",
    "# Seperate the two by subsetting.\n",
    "#####################\n",
    "\n",
    "# - Republicans\n",
    "df_r = df_voting[df_voting['party'] == 'republican']\n",
    "\n",
    "# Do not need party, it will just be in the way\n",
    "df_r = df_r.drop(['party'], axis = 1).reset_index()\n",
    "\n",
    "# - Democrats\n",
    "df_d = df_voting[df_voting['party'] == 'democrat']\n",
    "\n",
    "# Do not need party, it will just be in the way\n",
    "df_d = df_d.drop(['party'], axis = 1).reset_index()\n",
    "\n",
    "\n",
    "moe1, low1, mid1, high1 = ci(df_voting['religious-groups'].dropna(), 0.95)\n",
    "moe2, low2, mid2, high2 = ci(df_voting['budget'].dropna(), 0.95)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title(\"Percent of Republicans voting on bills\")\n",
    "\n",
    "ax.bar(x=0, height=mid1, yerr=moe1)\n",
    "ax.bar(x=1, height=mid2, yerr=moe2)\n",
    "\n",
    "\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_xticklabels([\"Religous Groups\", \"Budget Bill\"])\n",
    "plt.show()\n",
    "\n",
    "# Grab a sample\n",
    "\n",
    "small = df_voting.sample(40)\n",
    "\n",
    "# I have no real mental picture of how this works, but ehre anyway\n",
    "# Numpy complains about those stinking NaN's no matter what I command\n",
    "# it to do it seems, replacing them with 0 here\n",
    "\n",
    "small = small.replace({np.NaN:0})\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# My function to get Chi squared just vomits, continuously, so doing it with scipy\n",
    "stat, p, dof, exp = stats.chi2_contingency(small)\n",
    "print(stats)\n",
    "print(p)\n",
    "print(dof)\n",
    "print(exp)\n",
    "\n",
    "# TODO - your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ohsJhQUmEuS"
   },
   "source": [
    "## Stretch goals:\n",
    "\n",
    "1. Write a summary of your findings, mixing prose and math/code/results. *Note* - yes, this is by definition a political topic. It is challenging but important to keep your writing voice *neutral* and stick to the facts of the data. Data science often involves considering controversial issues, so it's important to be sensitive about them (especially if you want to publish).\n",
    "2. Apply the techniques you learned today to your project data or other data of your choice, and write/discuss your findings here.\n",
    "3. Refactor your code so it is elegant, readable, and can be easily run for all issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nyJ3ySr7R2k9"
   },
   "source": [
    "## Resources\n",
    "\n",
    "- [Interactive visualize the Chi-Squared test](https://homepage.divms.uiowa.edu/~mbognar/applets/chisq.html)\n",
    "- [Calculation of Chi-Squared test statistic](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test)\n",
    "- [Visualization of a confidence interval generated by R code](https://commons.wikimedia.org/wiki/File:Confidence-interval.svg)\n",
    "- [Expected value of a squared standard normal](https://math.stackexchange.com/questions/264061/expected-value-calculation-for-squared-normal-distribution) (it's 1 - which is why the expected value of a Chi-Squared with $n$ degrees of freedom is $n$, as it's the sum of $n$ squared standard normals)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_122_Sampling_Confidence_Intervals_and_Hypothesis_Testing_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}