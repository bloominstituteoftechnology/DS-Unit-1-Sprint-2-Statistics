{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "123 ZERNACH — Introduction to Bayesian Inference Assignment (Wednesday, October 9th 2019)).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zernach/DS-Unit-1-Sprint-2-Statistics/blob/master/123_ZERNACH_%E2%80%94_Introduction_to_Bayesian_Inference_Assignment_(Wednesday%2C_October_9th_2019)).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7OLbevlbd_Z",
        "colab_type": "text"
      },
      "source": [
        "# Lambda School Data Science Module 123\n",
        "\n",
        "## Introduction to Bayesian Inference\n",
        "\n",
        "ASSIGNMENT COMPLETED BY: [RYAN ZERNACH](https://ZERNACH.COM/RYAN-ZERNACH)\n",
        "\n",
        "![alt text](http://www.zernach.com/wp-content/uploads/2019/09/Ryan-Zernach-Logo-1-e1568499634499.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-DzzRk5bf0z",
        "colab_type": "text"
      },
      "source": [
        "## Assignment - Code it up!\n",
        "\n",
        "We used pure math to apply Bayes Theorem to drug tests. Now write Python code to reproduce the results! This is purposefully open ended - you'll have to think about how you should represent probabilities and events. You can and should look things up.\n",
        "\n",
        "Specific goals/targets:\n",
        "\n",
        "### 1) Write a function \n",
        "\n",
        "`def prob_drunk_given_positive(prob_drunk_prior, false_positive_rate):` \n",
        "\n",
        "You should only truly need these two values in order to apply Bayes Theorem. In this example, imagine that individuals are taking a breathalyzer test with an 8% false positive rate, a 100% true positive rate, and that our prior belief about drunk driving in the population is 1/1000. \n",
        " - What is the probability that a person is drunk after one positive breathalyzer test?\n",
        " - What is the probability that a person is drunk after two positive breathalyzer tests?\n",
        " - How many positive breathalyzer tests are needed in order to have a probability that's greater than 95% that a person is drunk beyond the legal limit?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpVhZyUnbf7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prob_drunk_given_positive(prob_drunk_prior, false_positive_rate):\n",
        "  #prob_of_true_positive\n",
        "  p1 = 1 - false_positive_rate\n",
        "\n",
        "  #prob_of_any_random_person_being_user\n",
        "  p2 = prob_drunk_prior\n",
        "\n",
        "  #prob_of_false_positive\n",
        "  p3 = false_positive_rate\n",
        "\n",
        "  #prob_of_any_random_person_being_non_user\n",
        "  p4 = 1 - prob_drunk_prior\n",
        "\n",
        "  bayes = (p1*p2) / ((p1*p2) + (p3*p4))\n",
        "\n",
        "  return bayes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMWdTan09TJk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "b2905de0-b25b-4009-c791-108e1bd617f1"
      },
      "source": [
        "# Breathalize/drug-screen once\n",
        "bayes_percent = prob_drunk_given_positive(0.001, 0.08)\n",
        "print(bayes_percent)\n",
        "\n",
        "#Breathalizer/drug-screen twice\n",
        "bayes_percent2 = prob_drunk_given_positive(bayes_percent, 0.08)\n",
        "print(bayes_percent2)\n",
        "\n",
        "#Breathalizer/drug-screen three times\n",
        "bayes_percent3 = prob_drunk_given_positive(bayes_percent2, 0.08)\n",
        "print(bayes_percent3)\n",
        "\n",
        "#Breathalizer/drug-screen four times\n",
        "bayes_percent4 = prob_drunk_given_positive(bayes_percent3, 0.08)\n",
        "print(bayes_percent4)\n",
        "\n",
        "#Breathlizer/drug-screen five times\n",
        "bayes_percent5 = prob_drunk_given_positive(bayes_percent4, 0.08)\n",
        "print(bayes_percent5)\n",
        "\n",
        "#THE FOURTH BREATHALIZER/DRUG-SCREEN GETS VERY CLOSE TO 95%\n",
        "#BUT WOULD ONLY BE CONSIDERED 95% IF YOU ROUND UP\n",
        "#SO A FIFTH TIME IS REQUIRED TO SUCCESSFULLY SURPASS THE 95TH ACCURACY PERCENTILE"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.011380504700643244\n",
            "0.11690607734806628\n",
            "0.6035517634803313\n",
            "0.9459680554381814\n",
            "0.9950577515521439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBr7Luuv5NzB",
        "colab_type": "text"
      },
      "source": [
        "### 2) Explore `scipy.stats.bayes_mvs`  \n",
        "Read its documentation, and experiment with it on data you've tested in other ways earlier this week.\n",
        " - Create a visualization comparing the results of a Bayesian approach to a traditional/frequentist approach. (with a large sample size they should look close to identical, however, take this opportunity to practice visualizing condfidence intervals in general. The following are some potential ways that you could visualize confidence intervals on your graph:\n",
        "  - [Matplotlib Error Bars](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.errorbar.html)\n",
        "  - [Seaborn barplot with error bars](https://seaborn.pydata.org/generated/seaborn.barplot.html)\n",
        "  - [Vertical ines to show bounds of confidence interval](https://www.simplypsychology.org/confidence-interval.jpg)\n",
        "  - [Confidence Intervals on Box Plots](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.axes.Axes.boxplot.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKfVSq0c5NCs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "644d3475-fcda-4226-faf1-3e87b4952c5a"
      },
      "source": [
        "from scipy import stats\n",
        "help(stats.bayes_mvs)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function bayes_mvs in module scipy.stats.morestats:\n",
            "\n",
            "bayes_mvs(data, alpha=0.9)\n",
            "    Bayesian confidence intervals for the mean, var, and std.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    data : array_like\n",
            "        Input data, if multi-dimensional it is flattened to 1-D by `bayes_mvs`.\n",
            "        Requires 2 or more data points.\n",
            "    alpha : float, optional\n",
            "        Probability that the returned confidence interval contains\n",
            "        the true parameter.\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    mean_cntr, var_cntr, std_cntr : tuple\n",
            "        The three results are for the mean, variance and standard deviation,\n",
            "        respectively.  Each result is a tuple of the form::\n",
            "    \n",
            "            (center, (lower, upper))\n",
            "    \n",
            "        with `center` the mean of the conditional pdf of the value given the\n",
            "        data, and `(lower, upper)` a confidence interval, centered on the\n",
            "        median, containing the estimate to a probability ``alpha``.\n",
            "    \n",
            "    See Also\n",
            "    --------\n",
            "    mvsdist\n",
            "    \n",
            "    Notes\n",
            "    -----\n",
            "    Each tuple of mean, variance, and standard deviation estimates represent\n",
            "    the (center, (lower, upper)) with center the mean of the conditional pdf\n",
            "    of the value given the data and (lower, upper) is a confidence interval\n",
            "    centered on the median, containing the estimate to a probability\n",
            "    ``alpha``.\n",
            "    \n",
            "    Converts data to 1-D and assumes all data has the same mean and variance.\n",
            "    Uses Jeffrey's prior for variance and std.\n",
            "    \n",
            "    Equivalent to ``tuple((x.mean(), x.interval(alpha)) for x in mvsdist(dat))``\n",
            "    \n",
            "    References\n",
            "    ----------\n",
            "    T.E. Oliphant, \"A Bayesian perspective on estimating mean, variance, and\n",
            "    standard-deviation from data\", https://scholarsarchive.byu.edu/facpub/278,\n",
            "    2006.\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    First a basic example to demonstrate the outputs:\n",
            "    \n",
            "    >>> from scipy import stats\n",
            "    >>> data = [6, 9, 12, 7, 8, 8, 13]\n",
            "    >>> mean, var, std = stats.bayes_mvs(data)\n",
            "    >>> mean\n",
            "    Mean(statistic=9.0, minmax=(7.103650222612533, 10.896349777387467))\n",
            "    >>> var\n",
            "    Variance(statistic=10.0, minmax=(3.176724206..., 24.45910382...))\n",
            "    >>> std\n",
            "    Std_dev(statistic=2.9724954732045084, minmax=(1.7823367265645143, 4.945614605014631))\n",
            "    \n",
            "    Now we generate some normally distributed random data, and get estimates of\n",
            "    mean and standard deviation with 95% confidence intervals for those\n",
            "    estimates:\n",
            "    \n",
            "    >>> n_samples = 100000\n",
            "    >>> data = stats.norm.rvs(size=n_samples)\n",
            "    >>> res_mean, res_var, res_std = stats.bayes_mvs(data, alpha=0.95)\n",
            "    \n",
            "    >>> import matplotlib.pyplot as plt\n",
            "    >>> fig = plt.figure()\n",
            "    >>> ax = fig.add_subplot(111)\n",
            "    >>> ax.hist(data, bins=100, density=True, label='Histogram of data')\n",
            "    >>> ax.vlines(res_mean.statistic, 0, 0.5, colors='r', label='Estimated mean')\n",
            "    >>> ax.axvspan(res_mean.minmax[0],res_mean.minmax[1], facecolor='r',\n",
            "    ...            alpha=0.2, label=r'Estimated mean (95% limits)')\n",
            "    >>> ax.vlines(res_std.statistic, 0, 0.5, colors='g', label='Estimated scale')\n",
            "    >>> ax.axvspan(res_std.minmax[0],res_std.minmax[1], facecolor='g', alpha=0.2,\n",
            "    ...            label=r'Estimated scale (95% limits)')\n",
            "    \n",
            "    >>> ax.legend(fontsize=10)\n",
            "    >>> ax.set_xlim([-4, 4])\n",
            "    >>> ax.set_ylim([0, 0.5])\n",
            "    >>> plt.show()\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIrzKR9WGpYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9771cc62-7570-407b-a9ab-00061cdb9fb0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "reefs = pd.read_csv('http://www.zernach.com/wp-content/uploads/2019/10/CoralBleaching.csv')\n",
        "\n",
        "reefs_no_unknowns = reefs[(reefs['SEVERITY_CODE']==0) | (reefs['SEVERITY_CODE']==1) | \n",
        "      (reefs['SEVERITY_CODE']==2) | (reefs['SEVERITY_CODE']==3)]\n",
        "\n",
        "stats.bayes_mvs(reefs_no_unknowns['SEVERITY_CODE'], alpha=.95)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Mean(statistic=1.3563840448987774, minmax=(1.3248516674305078, 1.387916422367047)),\n",
              " Variance(statistic=1.2913107172118607, minmax=(1.2406364949039308, 1.3419849395197907)),\n",
              " Std_dev(statistic=1.1363585337435806, minmax=(1.1140617758088334, 1.158655291678328)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc7Z0sI_Gz_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def confidence_int(input_data, confidence_level):\n",
        "  data = np.array(input_data.dropna()) #make sure the input data has no NaN values, and is in an array format\n",
        "  mean = np.mean(data) #mean of the points in the dataset\n",
        "  n = len(data) #number of data points in the dataset\n",
        "  sem = stats.sem(data) #SEM — the standard error of the mean (or standard error of measurement)\n",
        "  margin_of_error = sem * stats.t.ppf(((1 + confidence_level)/2.0), (n - 1))\n",
        "  lower_bound = mean - margin_of_error\n",
        "  upper_bound = mean + margin_of_error\n",
        "  print(' Mean: ', mean, '\\n Lower Bound: ', lower_bound, '\\n Upper Bound: ', upper_bound)\n",
        "  return (mean, lower_bound, upper_bound)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F2jBwCULTYg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c2169120-6c50-4529-afd5-aee93785de57"
      },
      "source": [
        "(mean, lower_bound, upper_bound) = confidence_int(reefs_no_unknowns['SEVERITY_CODE'], .95)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Mean:  1.3563840448987774 \n",
            " Lower Bound:  1.3248408526736621 \n",
            " Upper Bound:  1.3879272371238927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EilysW2mL83h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "e6655b31-48c4-4a2b-fc65-7be261a3c952"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "spread = 4\n",
        "data = (spread, mean, upper_bound, lower_bound)\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.set_title('Basic Plot')\n",
        "ax1.boxplot(data);"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS1KDjLskNej/AaPoly0hAOI4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv0prZYM5Rna",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### 3) In your own words, summarize the difference between Bayesian and Frequentist statistics\n",
        "\n",
        "If you're unsure where to start, check out [this blog post of Bayes theorem with Python](https://dataconomy.com/2015/02/introduction-to-bayes-theorem-with-python/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wblYkZT5Srp",
        "colab_type": "code",
        "colab": {},
        "cellView": "code"
      },
      "source": [
        "#@title Default title text\n",
        "#If the sample size is small, then use Bayesians. To ensure the validity\n",
        "# and accuracy of the test, one would include \"prior domain knowledge\" of the topic\n",
        "# that's being tested — which would be mathematically factored into the results\n",
        "# to increase (or decrease) the tester's confidence in the accuracy of the results.\n",
        "# \n",
        "# \n",
        "# If the sample size is large, then as the tester, you're already a frequentist.\n",
        "# A frequentists approach is to just run the test a bunch of times, and just let\n",
        "# the data speak for itself, which isn't a bad thing, but sometimes that's just\n",
        "# not possible due to time constraints, financial constraints, or a lack of clearly\n",
        "# organized datasets.\n",
        "# \n",
        "# \n",
        "# Ryan Allred (in the DS7 video of this topic) joked about there being a seismic\n",
        "# fissure that separates the frequentists from the Bayesians. But really, when deciding\n",
        "# which confidence/accuracy method you use, it just boils down to what's being tested,\n",
        "# whether there may (or may not) exist sample bias, and how large the sample size is."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWgWjp3PQ3Sq",
        "colab_type": "text"
      },
      "source": [
        "## Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRgHqmYIQ9qn",
        "colab_type": "text"
      },
      "source": [
        "- [Worked example of Bayes rule calculation](https://en.wikipedia.org/wiki/Bayes'_theorem#Examples) (helpful as it fully breaks out the denominator)\n",
        "- [Source code for mvsdist in scipy](https://github.com/scipy/scipy/blob/90534919e139d2a81c24bf08341734ff41a3db12/scipy/stats/morestats.py#L139)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP7Jv1XvwtkX",
        "colab_type": "text"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Go back and study the content from Modules 1 & 2 to make sure that you're really comfortable with them.\n",
        "- Apply a Bayesian technique to a problem you previously worked (in an assignment or project work) on from a frequentist (standard) perspective\n",
        "- Check out [PyMC3](https://docs.pymc.io/) (note this goes beyond hypothesis tests into modeling) - read the guides and work through some examples\n",
        "- Take PyMC3 further - see if you can build something with it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDi0eFr1x-v_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}